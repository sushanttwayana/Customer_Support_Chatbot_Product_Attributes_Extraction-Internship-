{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69fc716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase  # Connect to the mysql database\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "load_dotenv()\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.messages import HumanMessage,AnyMessage,AIMessage,ToolMessage,SystemMessage\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor , create_openai_tools_agent\n",
    "from langchain.prompts import ChatPromptTemplate,HumanMessagePromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda,RunnableParallel,RunnablePassthrough,RunnableSequence\n",
    "from langchain_core.messages import trim_messages\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f7e49",
   "metadata": {},
   "source": [
    "# 1. Connect to Mysql Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cdd259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded URI: mysql+pymysql://root:Sushant%4045%23@127.0.0.1/nepa_wholesale\n",
      "Database connection successful!\n",
      "Available tables: ['cigars_category', 'disposable_category', 'tobaccos_category']\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import quote_plus\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# Credentials\n",
    "username = 'root'\n",
    "password = 'Sushant@45#'  # Original password with special characters\n",
    "host = '127.0.0.1'\n",
    "db_name = 'nepa_wholesale'\n",
    "\n",
    "# URL encode the password to handle special characters\n",
    "encoded_password = quote_plus(password)\n",
    "\n",
    "# Create the MySQL URI with encoded password\n",
    "mysql_uri = f\"mysql+pymysql://{username}:{encoded_password}@{host}/{db_name}\"\n",
    "\n",
    "print(f\"Encoded URI: {mysql_uri}\")\n",
    "\n",
    "# Create database connection\n",
    "try:\n",
    "    db = SQLDatabase.from_uri(mysql_uri, sample_rows_in_table_info=2)\n",
    "    print(\"Database connection successful!\")\n",
    "    \n",
    "    # Test the connection\n",
    "    tables = db.get_usable_table_names()\n",
    "    print(f\"Available tables: {tables}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c2aadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql\n",
      "['cigars_category', 'disposable_category', 'tobaccos_category']\n"
     ]
    }
   ],
   "source": [
    "print(db.dialect)\n",
    "print(db.get_usable_table_names()) # to get the name of tables\n",
    "# print(db.get_table_info()) # to get the schema of the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd20547",
   "metadata": {},
   "source": [
    "# 2. Initialize the llm and embedding-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc50175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can use ChatGroq without explicitly passing the API key\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c22952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "232bab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Sushant\\product_bot\\cus_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Sushant\\product_bot\\cus_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d89a6",
   "metadata": {},
   "source": [
    "# 3. Creating fewshot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "658c2c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        'question': \"How many products of fronto are there in tobaccos ?\",\n",
    "        'query': \"SELECT COUNT(*) FROM tobaccos_category WHERE Brand LIKE '%FRONTO%';\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"How many products are there in tobaccos with flavor mint\",\n",
    "        'query': \"SELECT COUNT(Product_ID) FROM tobaccos_category WHERE Flavor LIKE '%mint%';\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"How many products are there in disposable having nicotine less than 5%. list them ?\",\n",
    "        'query': \"SELECT Product_ID, Display_Name, Nicotine_strength FROM disposable_category WHERE CAST(REPLACE(Nicotine_strength, '%', '') AS DECIMAL(3,2)) < 5 LIMIT 5;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"Which flavors of cigars have 'Raspberry' in them?\",\n",
    "        'query': \"SELECT Flavor FROM cigars_category WHERE Flavor LIKE '%Raspberry%' LIMIT 5;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"List disposable products with nicotine strength of 2%\",\n",
    "        'query': \"SELECT Display_Name, Nicotine_strength FROM disposable_category WHERE Nicotine_strength LIKE '%2%%' LIMIT 5;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I’m looking for cigar products from AL CAPONE. What do you have?\",\n",
    "        'query': \"SELECT Display_Name, Flavor FROM cigars_category WHERE Brand LIKE '%AL CAPONE%' LIMIT 5;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"How many unique flavors are offered in disposable products with 5000 puffs?\",\n",
    "        'query': \"SELECT COUNT(DISTINCT Flavor) FROM disposable_category WHERE Puff_count = 5000;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"I’m looking for cigars that come in a 12PK. What options do you have?\",\n",
    "        'query': \"SELECT Display_Name, Brand, Flavor FROM cigars_category WHERE Packet_count LIKE '%12PK%' LIMIT 5;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"Get the top 5 disposable products with the highest puff count.\",\n",
    "        'query': \"SELECT Display_Name, Puff_count FROM disposable_category ORDER BY Puff_count DESC LIMIT 5;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"Which brands offer disposable products with puff count equal to 5000?\",\n",
    "        'query': \"SELECT DISTINCT Brand FROM disposable_category WHERE Puff_count = 5000 LIMIT 5;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"How many products are there in DEATH ROW DISPOSABLE sub-category with 2% nicotine and 5 pack count?\",\n",
    "        'query': \"SELECT COUNT(*) FROM disposable_category WHERE Product_Sub_Category LIKE '%DEATH ROW DISPOSABLE%' AND Nicotine_strength LIKE '%2%%' AND Pack_count = 5;\"\n",
    "    },\n",
    "    {\n",
    "        'question': \"How many different cigar flavors do you offer?\",\n",
    "        'query': \"SELECT COUNT(DISTINCT Flavor) FROM cigars_category;\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b326f",
   "metadata": {},
   "source": [
    "# 4. Creating the vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33adcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\n",
    "    embedding_function = embedding_model, # Embedding model\n",
    "    collection_name = \"example_collection\", # Table name in vectorstore\n",
    "    persist_directory=\"./chroma_db\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eece374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addind the examples in vectorstore (Only questions as text and entire 'question and query' in metadata)\n",
    "vectorstore.add_texts([ex['question'] for ex in examples],metadatas=examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6877a0aa",
   "metadata": {},
   "source": [
    "# 5. Defining the examples selector from vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3136522",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=1 , \n",
    "    input_keys = ['question'],   # Which key to use for similarity search\n",
    "    example_keys=['question','query'] # Which keys to return\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1335e8",
   "metadata": {},
   "source": [
    "# 6. Build dynamic prompt with : prompt + examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dynamic_prefix(user_question: str) -> str:\n",
    "    # print(messages[-1].content)\n",
    "    # print(user_question)\n",
    "    # user_question = messages\n",
    "    # print(f\"***** Selectiong Dynamic example using this question***** {user_question}\")\n",
    "    # user_question = \n",
    "    selected = example_selector.select_examples({\"question\": user_question})\n",
    "    formatted_examples = \"\\n\".join([\n",
    "        f\"Human: {ex['question']}\\nAI:\\nSQLQuery: {ex['query']}\" for ex in selected\n",
    "    ])\n",
    "    return f\"\"\"User Question to answer :  {user_question}\n",
    "\n",
    "Refer to the below given most similar examples to answer the above user question . \n",
    "\n",
    "Examples:\n",
    "{formatted_examples}\n",
    "...\n",
    "\n",
    "Now begin.\n",
    "\"\"\"\n",
    "# dynamic_prefix = build_dynamic_prefix(\"what is my income of last year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c40b63",
   "metadata": {},
   "source": [
    "# 7. Using Create_SQL_agent with agent_type \"Openai_Functions\"\n",
    "\n",
    "### Note : Only works with 'OPEN-AI MODELS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ceb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tool to get the list of tables from database\n",
    "@tool\n",
    "def list_tables(_: str = \"\") -> str:\n",
    "    \"\"\"Use this tool to list all table names that exist in the connected MySQL database. Pass an empty string to get the list of available tables\n",
    "    This is helpful when you need to know what tables are available before writing a SQL query.\"\"\"\n",
    "    return str(db.get_table_names())\n",
    "\n",
    "\n",
    "# tool to get schema of table to be used\n",
    "@tool\n",
    "def describe_table(table_name: str) -> str:\n",
    "    \"\"\"Use this tool to get the schema (column names and types) of a specific table.Input should be the name of the table as a string. \n",
    "    This is useful to understand what data is stored in the table before writing queries.\"\"\"\n",
    "    return str(db.get_table_info([table_name]))\n",
    "\n",
    "# tool to execute the sql query in database\n",
    "@tool\n",
    "def run_sql_query(query: str) -> str:\n",
    "    \"\"\"Use this tool to run a raw SQL query on the database and return the result.\n",
    "    Input should be a complete and valid SQL SELECT query as a string. \n",
    "    Use this when you already know which table and columns to query.\"\"\"\n",
    "    return str(db.run(query))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e0330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_sql_query.name)  #to get the name of the tool\n",
    "print(run_sql_query.description) #to get the description of the tool\n",
    "print(run_sql_query.args) # to get the input arguments to the tools \n",
    "print(run_sql_query.args_schema.model_json_schema()) # to get the schmea of the tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a754d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_msg = \"\"\"You are a helpful assistant that uses tools to interact with a MySQL database. Create a syntactically correct MySQL query to run, execute the Query and return the final response in natural language back, after proper formatting.\n",
    "You have access to the following tools, Use the 'list_tables' tools to identify the list of available tables and decide which table to use and then use 'describe_table' tool and based on the results from both generate SQL query and use 'run_sql_query' tool.\n",
    "1. list_tables: List all available tables. \n",
    "2. describe_table: Get the schema of a table. \n",
    "3. run_sql_query: Run a raw SQL query. \n",
    "\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Do not hallicunate and incase you do not find the answer respond with \"Sorry I am unable to answer your question\".\n",
    "\n",
    "Below given is the chat history betwen the human and the agent. Also handle the follow up question and use the tools provided if you need .\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ed6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim messages to keep last 2 conversation\n",
    "def conversational_window_memory(messages):\n",
    "    selected_msg = trim_messages(\n",
    "    messages,\n",
    "    token_counter=len,  \n",
    "    max_tokens=2,  \n",
    "    strategy=\"last\",\n",
    "    \n",
    "    start_on=\"human\",\n",
    "\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "\n",
    "    )\n",
    "    return selected_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572845eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [list_tables,describe_table,run_sql_query]\n",
    "\n",
    "def initialize_agent(prompt):\n",
    "    agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "\n",
    "    agent_executor2 = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "    return agent , agent_executor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62344fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assembling all the components\n",
    "\n",
    "user_question = input(\"Enter the query: \")\n",
    "if user_question:\n",
    "    \n",
    "    dynamic_prefix = build_dynamic_prefix(user_question) # User question + 1 most similar examples from vectorstore\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([          # Prompt to agent that conist of : system prompt + chat_history + user_question and dynamic example + Empty agent scratchpad\n",
    "    (\"system\", system_msg),\n",
    "\n",
    "    MessagesPlaceholder(variable_name = \"chat_history\"),\n",
    "\n",
    "    (\"human\",dynamic_prefix),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")  #\n",
    "])\n",
    "    \n",
    "    agent,agent_executor = initialize_agent(prompt)  # Initialize the agent and agent executor with the prompt\n",
    "\n",
    "    response = agent_executor.invoke({               # Invoke the agent with empty \"\" input and chat_history\n",
    "    \"chat_history\" : chat_history \n",
    "    })\n",
    "    print(f\"User Question: {user_question}\")\n",
    "    print(f\"Agent: {response}\")\n",
    "\n",
    "    chat_history.append(HumanMessage(content=user_question))        # Appedn the user question to chat_history\n",
    "\n",
    "    chat_history.append(AIMessage(response['output']))                #Append the agent's final response to chat_history\n",
    "\n",
    "    chat_history = conversational_window_memory(chat_history)          # Trim to keep only 2 msg (equivalent to 1 conversation between human and agent)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"User Question: {user_question}\")\n",
    "print(f\"Agent: {response['output']}\")\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba24905c",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cus_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
